{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Data Collection\n",
    "\n",
    "If you ran through the basic motion notebook, hopefully you're enjoying how easy it can be to make your Jetbot move around! Thats very cool!  But what's even cooler, is making JetBot move around all by itself!  \n",
    "\n",
    "This is a super hard task, that has many different approaches but the whole problem is usually broken down into easier sub-problems.  It could be argued that one of the most\n",
    "important sub-problems to solve, is the problem of preventing the robot from entering dangerous situations!  We're calling this *collision avoidance*. \n",
    "\n",
    "In this set of notebooks, we're going to attempt to solve the problem using deep learning and a single, very versatile, sensor: the camera.  You'll see how with a neural network, camera, and the NVIDIA Jetson Nano, we can teach the robot a very useful behavior!\n",
    "\n",
    "The approach we take to avoiding collisions is to create a virtual \"safety bubble\" around the robot.  Within this safety bubble, the robot is able to spin in a circle without hitting any objects (or other dangerous situations like falling off a ledge).  \n",
    "\n",
    "# 충돌 회피-데이터 수집\n",
    "\n",
    "- 기본 모션 노트북을 살펴 본다면 Jetbot이 얼마나 쉽게 움직일 수 있을지 기대됩니다! 정말 멋지다! 그러나 더 멋진 점은 JetBot 자체를 모두 움직이게 만드는 것입니다!\n",
    "\n",
    "- 이것은 매우 어려운 작업이며 많은 다른 접근 방식이 있지만 전체 문제는 일반적으로 더 쉬운 하위 문제로 나뉩니다. 그것은 가장 중 하나라고 주장 할 수있다.\n",
    "- 해결해야 할 중요한 하위 문제는 로봇이 위험한 상황에 들어 가지 못하게하는 문제입니다! 이를 \"충돌 방지\"라고합니다.\n",
    "\n",
    "- 이 노트북 세트에서는 딥 러닝과 매우 다양한 단일 센서 인 카메라를 사용하여 문제를 해결하려고합니다. 신경망, 카메라 및 NVIDIA Jetson Nano를 사용하여 로봇에게 매우 유용한 동작을 배울 수있는 방법을 알 수 있습니다!\n",
    "\n",
    "- 충돌을 피하기 위해 접근하는 방법은 로봇 주위에 가상의 \"안전 버블\"을 만드는 것입니다. 이 안전 버블 내에서 로봇은 물체 (또는 난간에서 떨어지는 것과 같은 다른 위험한 상황)에 부딪치지 않고 원형으로 회전 할 수 있습니다.\n",
    "\n",
    "# \n",
    "\n",
    "Of course, the robot is limited by what's in it's field of vision, and we can't prevent objects from being placed behind the robot, etc.  But we can prevent the robot from entering these scenarios itself.\n",
    "\n",
    "The way we'll do this is super simple:  \n",
    "\n",
    "First, we'll manually place the robot in scenarios where it's \"safety bubble\" is violated, and label these scenarios ``blocked``.  We save a snapshot of what the robot sees along with this label.\n",
    "\n",
    "Second, we'll manually place the robot in scenarios where it's safe to move forward a bit, and label these scenarios ``free``.  Likewise, we save a snapshot along with this label.\n",
    "\n",
    "That's all that we'll do in this notebook; data collection.  Once we have lots of images and labels, we'll upload this data to a GPU enabled machine where we'll *train* a neural network to predict whether the robot's safety bubble is being violated based off of the image it sees.  We'll use this to implement a simple collision avoidance behavior in the end :)\n",
    "\n",
    "> IMPORTANT NOTE:  When JetBot spins in place, it actually spins about the center between the two wheels, not the center of the robot chassis itself.  This is an important detail to remember when you're trying to estimate whether the robot's safety bubble is violated or not.  But don't worry, you don't have to be exact. If in doubt it's better to lean on the cautious side (a big safety bubble).  We want to make sure JetBot doesn't enter a scenario that it couldn't get out of by turning in place.\n",
    "\n",
    "- 물론 로봇은 시야에있는 것에 의해 제한되며, 물체가 로봇 뒤에 놓이는 것을 막을 수는 없습니다. 그러나 로봇이 이러한 시나리오 자체에 들어가는 것을 막을 수는 있습니다.\n",
    "\n",
    "- 우리가하는 방법은 매우 간단합니다.\n",
    "\n",
    "- 먼저 \"안전 버블\"을 위반 한 시나리오에 로봇을 수동으로 배치하고 이러한 시나리오에 '차단'레이블을 붙입니다. 이 라벨과 함께 로봇이 보는 것의 스냅 샷을 저장합니다.\n",
    "\n",
    "- 둘째, 조금 앞으로 나아가도 안전한 시나리오에 로봇을 수동으로 배치하고 이러한 시나리오에 '무료'라는 레이블을 붙입니다. 마찬가지로이 레이블과 함께 스냅 샷을 저장합니다.\n",
    "\n",
    "- 이것이 우리가이 공책에서 할 모든 것입니다. 데이터 수집. 이미지와 레이블이 많으면이 데이터를 GPU 지원 머신에 업로드하여 신경망을 * 훈련 *하여 로봇의 안전 버블이 보이는 이미지를 기반으로 위반되는지 여부를 예측합니다. 우리는 이것을 사용하여 결국 간단한 충돌 회피 동작을 구현할 것입니다 :)\n",
    "\n",
    "> 중요 참고 : JetBot이 제자리에서 회전하면 실제로 로봇 섀시 자체의 중심이 아니라 두 바퀴 사이의 중심을 중심으로 회전합니다. 이것은 로봇의 안전 버블이 위반되는지 여부를 추정 할 때 기억해야 할 중요한 세부 사항입니다. 하지만 걱정할 필요는 없습니다. 정확할 필요는 없습니다. 의심스러운 경우 신중한 측면 (큰 안전 버블)에 기대는 것이 좋습니다. 우리는 JetBot이 제자리를 돌려도 벗어날 수없는 시나리오에 들어 가지 않도록하고 싶습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display live camera feed\n",
    "\n",
    "So let's get started.  First, let's initialize and display our camera like we did in the *teleoperation* notebook.  \n",
    "\n",
    "> Our neural network takes a 224x224 pixel image as input.  We'll set our camera to that size to minimize the filesize of our dataset (we've tested that it works for this task).\n",
    "> In some scenarios it may be better to collect data in a larger image size and downscale to the desired size later.\n",
    "\n",
    "\n",
    "### 라이브 카메라 피드 표시\n",
    "\n",
    "- 이제 시작하겠습니다. 먼저, * teleoperation * 노트북에서와 같이 카메라를 초기화하고 표시해 봅시다.\n",
    "\n",
    "> 우리의 신경망은 224x224 픽셀 이미지를 입력으로 사용합니다. 데이터 세트의 파일 크기를 최소화하기 위해 카메라를 해당 크기로 설정합니다 (이 작업에서 작동하는지 테스트했습니다).\n",
    "> 일부 시나리오에서는 더 큰 이미지 크기로 데이터를 수집하고 나중에 원하는 크기로 축소하는 것이 좋습니다.\n",
    "\n",
    "- 아래 코드에서 Waring이 발생하지만 정상동작하는데에 지장이 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780404e9dbd3439f8cef9eca8b7fd300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, next let's create a few directories where we'll store all our data.  We'll create a folder ``dataset`` that will contain two sub-folders ``free`` and ``blocked``, \n",
    "where we'll place the images for each scenario.\n",
    "\n",
    "- 다음으로 모든 데이터를 저장할 디렉토리를 몇 개 만듭니다. 우리는 두 개의 하위 폴더 'free'와 'blocked'를 포함하는 'dataset' 폴더를 만들 것입니다.\n",
    "- 각 시나리오에 대한 이미지를 배치 할 위치입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "blocked_dir = 'dataset/blocked'\n",
    "free_dir = 'dataset/free'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(free_dir)\n",
    "    os.makedirs(blocked_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you refresh the Jupyter file browser on the left, you should now see those directories appear.  Next, let's create and display some buttons that we'll use to save snapshots\n",
    "for each class label.  We'll also add some text boxes that will display how many images of each category that we've collected so far. This is useful because we want to make\n",
    "sure we collect about as many ``free`` images as ``blocked`` images.  It also helps to know how many images we've collected overall.\n",
    "\n",
    "- 왼쪽의 Jupyter 파일 브라우저를 새로 고치면 해당 디렉토리가 나타납니다. 다음으로, 스냅 샷을 저장하는 데 사용할 몇 가지 버튼을 만들고 표시하겠습니다.\n",
    "- 각 클래스 레이블마다. 또한 지금까지 수집 한 각 카테고리의 이미지 수를 표시하는 텍스트 상자를 추가합니다. 이것은 우리가 만들고 싶어하기 때문에 유용합니다\n",
    "- 우리는 'blocked'이미지만큼 많은 'free' 이미지를 수집합니다. 또한 전체적으로 수집 한 이미지 수를 파악하는 데 도움이됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ad580d094459b86d334faf7d749bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='128px')), Button(button_style='success', d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc3e9ab238642f2937866b6bd63a8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='128px')), Button(button_style='danger', de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "free_button = widgets.Button(description='add free', button_style='success', layout=button_layout)\n",
    "blocked_button = widgets.Button(description='add blocked', button_style='danger', layout=button_layout)\n",
    "free_count = widgets.IntText(layout=button_layout, value=len(os.listdir(free_dir)))\n",
    "blocked_count = widgets.IntText(layout=button_layout, value=len(os.listdir(blocked_dir)))\n",
    "\n",
    "display(widgets.HBox([free_count, free_button]))\n",
    "display(widgets.HBox([blocked_count, blocked_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, these buttons wont do anything.  We have to attach functions to save images for each category to the buttons' ``on_click`` event.  We'll save the value\n",
    "of the ``Image`` widget (rather than the camera), because it's already in compressed JPEG format!\n",
    "\n",
    "To make sure we don't repeat any file names (even across different machines!) we'll use the ``uuid`` package in python, which defines the ``uuid1`` method to generate\n",
    "a unique identifier.  This unique identifier is generated from information like the current time and the machine address.\n",
    "\n",
    "- 지금이 버튼들은 아무 것도하지 않습니다. 각 범주의 이미지를 버튼의 'on_click'이벤트에 저장하는 기능을 추가해야합니다. 우리는 가치를 저장할 것입니다\n",
    "- 이미 압축 된 JPEG 형식이므로 '이미지'위젯 (카메라가 아닌) 위젯!\n",
    "\n",
    "- 다른 컴퓨터에서도 파일 이름을 반복하지 않도록 'uuid'패키지를 사용하여 'uuid1' 메소드를 정의합니다.\n",
    "- 고유 식별자 이 고유 식별자는 현재 시간 및 컴퓨터 주소와 같은 정보에서 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "\n",
    "def save_free():\n",
    "    global free_dir, free_count\n",
    "    save_snapshot(free_dir)\n",
    "    free_count.value = len(os.listdir(free_dir))\n",
    "    \n",
    "def save_blocked():\n",
    "    global blocked_dir, blocked_count\n",
    "    save_snapshot(blocked_dir)\n",
    "    blocked_count.value = len(os.listdir(blocked_dir))\n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "free_button.on_click(lambda x: save_free())\n",
    "blocked_button.on_click(lambda x: save_blocked())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now the buttons above should save images to the ``free`` and ``blocked`` directories.  You can use the Jupyter Lab file browser to view these files!\n",
    "\n",
    "Now go ahead and collect some data \n",
    "\n",
    "1. Place the robot in a scenario where it's blocked and press ``add blocked``\n",
    "2. Place the robot in a scenario where it's free and press ``add free``\n",
    "3. Repeat 1, 2\n",
    "\n",
    "> REMINDER: You can move the widgets to new windows by right clicking the cell and clicking ``Create New View for Output``.  Or, you can just re-display them\n",
    "> together as we will below\n",
    "\n",
    "Here are some tips for labeling data\n",
    "\n",
    "1. Try different orientations\n",
    "2. Try different lighting\n",
    "3. Try varied object / collision types; walls, ledges, objects\n",
    "4. Try different textured floors / objects;  patterned, smooth, glass, etc.\n",
    "\n",
    "Ultimately, the more data we have of scenarios the robot will encounter in the real world, the better our collision avoidance behavior will be.  It's important\n",
    "to get *varied* data (as described by the above tips) and not just a lot of data, but you'll probably need at least 100 images of each class (that's not a science, just a helpful tip here).  But don't worry, it goes pretty fast once you get going :)\n",
    "\n",
    "\n",
    "\n",
    "- 이제 위의 버튼은 이미지를 'free'및 'blocked'디렉토리에 저장해야합니다. \n",
    "- Jupyter Lab 파일 브라우저를 사용하여 이러한 파일을 볼 수 있습니다!\n",
    "\n",
    "- 이제 몇 가지 데이터를 수집하십시오.\n",
    "    1. 로봇이 차단 된 시나리오에 로봇을 놓고``추가 차단 ''을 누릅니다\n",
    "    2. 로봇이 자유로운 시나리오에 로봇을 놓고``무료 추가 ''를 누르십시오\n",
    "    3. 1, 2 반복\n",
    "\n",
    "> 알림 : 셀을 마우스 오른쪽 버튼으로 클릭하고``출력을위한 새보기 만들기 ''를 클릭하여 위젯을 새 창으로 이동할 수 있습니다. 또는 다시 표시 할 수 있습니다 아래에서와 같이\n",
    "\n",
    "- 다음은 데이터 라벨링을위한 팁입니다.(검색 키워드 : 데이터 어그멘테이션,image augmentation) 을 진행하면 노가다를 줄일수 있습니다!\n",
    "    1. 다른 방향으로 시도하십시오\n",
    "    2. 다른 조명을 사용해보십시오\n",
    "    3. 다양한 객체 / 충돌 유형을 시도하십시오. 벽, 선반, 물체\n",
    "    4. 다른 질감의 바닥 / 물체를 사용해보십시오. 패턴 화, 부드러운 유리 등\n",
    "\n",
    "- 궁극적으로 실제 세계에서 로봇이 직면하게 될 시나리오에 대한 데이터가 많을수록 충돌 회피 행동이 향상됩니다. 중요하다\n",
    "- 많은 데이터가 아니라 * 다양한 * 데이터 (위의 팁에서 설명)를 가져 오려면 각 클래스의 이미지가 100 개 이상 필요합니다 (과학이 아니라 유용한 팁). 그러나 걱정하지 마십시오. 일단 가면 꽤 빠릅니다. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780404e9dbd3439f8cef9eca8b7fd300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b54f63fa784463796ffad2dc405772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='128px')), Button(button_style='success', d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55b59a5d82b4ee4b7bf418ff198c4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='128px')), Button(button_style='danger', de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image)\n",
    "display(widgets.HBox([free_count, free_button]))\n",
    "display(widgets.HBox([blocked_count, blocked_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "Once you've collected enough data, we'll need to copy that data to our GPU desktop or cloud machine for training.  First, we can call the following *terminal* command to compress\n",
    "our dataset folder into a single *zip* file.\n",
    "\n",
    "> The ! prefix indicates that we want to run the cell as a *shell* (or *terminal*) command.\n",
    "\n",
    "> The -r flag in the zip command below indicates *recursive* so that we include all nested files, the -q flag indicates *quiet* so that the zip command doesn't print any output\n",
    "\n",
    "- 충분한 데이터를 수집 한 후에는 훈련을 위해 해당 데이터를 GPU 데스크톱 또는 클라우드 머신에 복사해야합니다. 먼저 다음 * terminal * 명령을 호출하여 압축 할 수 있습니다\n",
    "- 데이터 세트 폴더를 단일 * zip * 파일로 만듭니다.\n",
    "\n",
    ">! prefix는 셀을 * shell * (또는 * terminal *) 명령으로 실행하려고 함을 나타냅니다.\n",
    "\n",
    "> 아래 zip 명령의 -r 플래그는 모든 중첩 파일을 포함하도록 * recursive *를 나타내고, -q 플래그는 * quiet *를 나타내므로 zip 명령은 출력을 인쇄하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r -q dataset.zip dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a file named ``dataset.zip`` in the Jupyter Lab file browser.  You should download the zip file using the Jupyter Lab file browser by right clicking and selecting ``Download``.\n",
    "\n",
    "Next, we'll need to upload this data to our GPU desktop or cloud machine (we refer to this as the *host*) to train the collision avoidance neural network.  We'll assume that you've set up your training\n",
    "machine as described in the JetBot WiKi.  If you have, you can navigate to ``http://<host_ip_address>:8888`` to open up the Jupyter Lab environment running on the host.  The notebook you'll need to open there is called ``collision_avoidance/train_model.ipynb``.\n",
    "\n",
    "So head on over to your training machine and follow the instructions there!  Once your model is trained, we'll return to the robot Jupyter Lab enivornment to use the model for a live demo!\n",
    "\n",
    "- Jupyter Lab 파일 브라우저에 'dataset.zip'이라는 파일이 나타납니다. Jupyter Lab 파일 브라우저를 사용하여 마우스 오른쪽 버튼을 클릭하고 '다운로드'를 선택하여 zip 파일을 다운로드해야합니다.\n",
    "\n",
    "- 다음으로 충돌 회피 신경망을 훈련시키기 위해이 데이터를 GPU 데스크탑 또는 클라우드 머신 (이를 * 호스트 *)에 업로드해야합니다. 우리는 당신이 당신의 훈련을 설정했다고 가정합니다\n",
    "- JetBot WiKi에 설명 된대로 있다면 'http : // <host_ip_address> : 8888'로 이동하여 호스트에서 실행되는 Jupyter Lab 환경을 열 수 있습니다. 거기에서 열어야 할 노트북은 'collision_avoidance / train_model.ipynb'입니다.\n",
    "\n",
    "- 훈련 기계로 가서 지시 사항을 따르십시오! 모델 훈련이 완료되면 로봇 Jupyter Lab으로 돌아와 라이브 데모를 위해 모델을 사용합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
